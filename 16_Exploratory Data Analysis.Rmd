---
title: "16_Exploratory Data Analysis"
author: "Steve Chevalier"
date: "September 20, 2018"
output: html_document
---

```{r}
# get commics datasets
library(readr)
dc_comics <- read_csv("E:/One Drive/OneDrive/data_mining/comics/dc-wikia-data.csv")
comics <- data.frame(dc_comics)
# glimpse(comics)
# comics[] <-  lapply(comics, factor)
# comics$appearances <- as.integer(comics$appearances)
# comics$year <- as.integer(comics$year)
glimpse(comics)
# marvel_comics <- read_csv("E:/One Drive/OneDrive/data_mining/comics/marvel-wikia-data.csv")
```

```{r}
library(ggplot2)
```

```{r}
# Print the first rows of the data
head(comics)
# Check levels of align
levels(comics$align)
# Check the levels of gender
levels(comics$gender)
# Create a 2-way contingency table
table(comics$align,comics$gender)
```

Dropping levels
The contingency table from the last exercise revealed that there are some levels that have very low counts. To simplify the analysis, it often helps to drop such levels.

```{r}
# Load dplyr
library(dplyr)
# Remove align level
comics <- comics %>%
  filter(align != "Reformed Criminals") %>%
  droplevels()
```

**Exploring Categorical Data**

Side-by-side barcharts

While a contingency table represents the counts numerically, it's often more useful to represent them graphically.

Here you'll construct two side-by-side barcharts of the comics data. This shows that there can often be two or more options for presenting the same data. Passing the argument position = "dodge" to geom_bar() says that you want a side-by-side (i.e. not stacked) barchart.

```{r}
# Load ggplot2
library(ggplot2)

# Create side-by-side barchart of gender by alignment
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "dodge")

# Create side-by-side barchart of alignment by gender
ggplot(comics, aes(x = gender, fill = align)) + 
  geom_bar(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90))
```
Take a moment to toggle between the resulting plots in the plotting window. 


Counts vs. proportions

Conditional proportions

```{r}
tab <- table(comics$align, comics$gender)
options(scipen = 999, digits = 3) # Print fewer digits
prop.table(tab)     # Joint proportions
prop.table(tab, 2)  # Conditional on columns
```
Counts vs. proportions (2)

Bar charts can tell dramatically different stories depending on whether they represent counts or proportions and, if proportions, what the proportions are conditioned on. To demonstrate this difference, you'll construct two barcharts in this exercise: one of counts and one of proportions.
```{r}
# Plot of gender by align
ggplot(comics, aes(x = align, fill = gender)) +
  geom_bar()
  
# Plot proportion of gender, conditional on align
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "fill") +
  ylab("proportion")
```

By adding position = "fill" to geom_bar(), you are saying you want the bars to fill the entire height of the plotting window, thus displaying proportions and not raw counts. 

Marginal barchart

If you are interested in the distribution of alignment of all superheroes, it makes sense to construct a barchart for just that single variable.

You can improve the interpretability of the plot, though, by implementing some sensible ordering. Superheroes that are "Neutral" show an alignment between "Good" and "Bad", so it makes sense to put that bar in the middle.

```{r}
# Change the order of the levels in align
# this turns all of these to NA,  ??? odd
# comics$align <- factor(comics$align, levels = c("Bad","Neutral","Good"))

# Create plot of align
ggplot(comics, aes(x = align)) + 
  geom_bar()
```

Conditional barchart

Now, if you want to break down the distribution of alignment based on gender, you're looking for conditional distributions.

You could make these by creating multiple filtered datasets (one for each gender) or by faceting the plot of alignment based on gender. As a point of comparison, we've provided your plot of the marginal distribution of alignment from the last exercise.

```{r}
# Plot of alignment broken down by gender
ggplot(comics, aes(x = align)) + 
  geom_bar() +
  facet_wrap(~ gender)
```
Improve piechart

The piechart is a very common way to represent the distribution of a single categorical variable, but they can be more difficult to interpret than barcharts.

This is a piechart of a dataset called pies that contains the favorite pie flavors of 98 people. **Improve the representation of these data by constructing a barchart that is ordered in descending order of count.**

```{r}
# Put levels of flavor in decending order
lev <- c("apple", "key lime", "boston creme", "blueberry", "cherry", "pumpkin", "strawberry")
pies$flavor <- factor(pies$flavor, levels = lev)

# Create barchart of flavor
ggplot(pies, aes(x = flavor)) + 
  geom_bar(fill = "chartreuse") + 
  theme(axis.text.x = element_text(angle = 90))
```

**Exploring Numerical Data**
To get this version of cars.  On DCamp, issue **dput** (can use dget to get but or...) copy screen output to clipboar, in an empty R file type myCars <- and then past the copy.  Run it, save this to a database. (now in myCars, dbname = "d_camp_data")

```{r}
library(RPostgreSQL);library(dplyr)
library(DBI)
con_postgres <- dbConnect(PostgreSQL(), dbname = "d_camp_data",  
                         host = "127.0.0.1", port = 5432,
                         user = "postgres", password = "admin1")
myCars <- dbGetQuery(con_postgres, "select * from public.\"cars\";")
str(myCars)
```


```{r}
# Load package
library(ggplot2)
# Learn data structure
str(myCars)

# Create faceted histogram
ggplot(myCars, aes(x = city_mpg)) +
  geom_histogram() +
  facet_wrap(~ suv)
```
In this exercise, you faceted by the suv variable, but it's important to note that you can facet a plot by any categorical variable using facet_wrap()

Boxplots and density plots

The mileage of a car tends to be associated with the size of its engine (as measured by the number of cylinders). To explore the relationship between these two variables, you could stick to using histograms, but in this exercise you'll try your hand at two alternatives: the box plot and the density plot.

```{r}
unique(myCars$ncyl)
# Filter cars with 4, 6, 8 cylinders
common_cyl <- filter(myCars, ncyl %in% c(4,6,8))
# Create box plots of city mpg by ncyl
ggplot(common_cyl, aes(x = as.factor(ncyl), y = city_mpg)) +
  geom_boxplot()

# Create overlaid density plots for same data
ggplot(common_cyl, aes(x = city_mpg, fill = as.factor(ncyl))) +
  geom_density(alpha = .3)
```
The variability in mileage of 8 cylinder cars seem much smaller than that of 4 cylinder cars. 

Marginal and conditional histograms

Now, turn your attention to a new variable: horsepwr. The goal is to get a sense of the marginal distribution of this variable and then compare it to the distribution of horsepower conditional on the price of the car being less than $25,000.

You'll be making two plots using the "data pipeline" paradigm, where you start with the raw data and end with the plot.

```{r}
# Create hist of horsepwr
myCars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram() +
  ggtitle("Distribution of horsepower")

# Create hist of horsepwr for affordable cars
myCars %>% 
  filter(msrp < 25000) %>%
  ggplot(aes(horsepwr)) +
  geom_histogram() +
  xlim(c(90, 550)) +
  ggtitle("Distribution of horsepower for cars under $25k")
```
Marginal and conditional histograms interpretation

Observe the two histograms in the plotting window and decide which of the following is a valid interpretation.

**The highest horsepower car in the less expensive range has just under 250 horsepower.**

```{r}
# Create hist of horsepwr with binwidth of 3
myCars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 3) +
  ggtitle("binwidth = 3")

# Create hist of horsepwr with binwidth of 30
myCars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 30) +
  ggtitle("binwidth = 30")

# Create hist of horsepwr with binwidth of 60
myCars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 60) +
  ggtitle("binwidth = 60")

```
Three binwidths interpretation

What feature is present in Plot A that's not found in B or C?

  **There is a tendency for cars to have horsepower right at 200 or 300 horsepower.**

```{r}
library(ggplot2)
# Construct box plot of msrp
myCars %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()

# Exclude outliers from data
cars_no_out <- myCars %>%
  filter(msrp < 100000)

# Construct box plot of msrp using the reduced dataset
cars_no_out %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()
```
Be sure to toggle back and forth in the plots pane to compare the box plots. 

Plot selection

Consider two other columns in the cars dataset: city_mpg and width. Which is the most appropriate plot for displaying the important features of their distributions? Remember, both density plots and box plots display the central tendency and spread of the data, but the box plot is more robust to outliers.

```{r}
# Create plot of city_mpg
myCars %>%
  ggplot(aes(x = 1, y = city_mpg)) +
  geom_boxplot()

# Create plot of width
myCars %>% 
  ggplot(aes(x = width)) +
  geom_density()
```
Because the city_mpg variable has a much wider range with its outliers, it's best to display its distribution as a box plot. 

3 variable plot

Faceting is a valuable technique for looking at several conditional distributions at the same time. If the faceted distributions are laid out in a grid, you can consider the association between a variable and two others, one on the rows of the grid and the other on the columns.

```{r}
# Facet hists using hwy mileage and ncyl
myCars %>% 
  filter(ncyl %in% c(4,6,8)) %>%
  ggplot(aes(x = hwy_mpg)) +
  geom_histogram() +
  facet_grid(ncyl ~ suv) +
  ggtitle("Mileage by suv and ncyl")
```



**Numerical Summaries**
```{r}
x <- c(76,78,75,74,76,72,74,73,73,75,74)
table(x);mean(x);median(x)# ;mode(x) most common
var(x) #sample variance, one of the most useful measurements of the spread of a distribution
sd(x) # sample standard deviation, same unit as the original data
# IQR interquartile range
summary(x);IQR(x) # best with outliers
# the range = max(x)-min(x)
max(x)-min(x)
diff(range(x))
```

Calculate center measures

Throughout this chapter, you will use data from gapminder, which tracks demographic data in countries of the world over time. To learn more about it, you can bring up the help file with ?gapminder.

For this exercise, focus on how the life expectancy differs from continent to continent. This requires that you conduct your analysis not at the country level, but aggregated up to the continent level. This is made possible by the one-two punch of group_by() and summarize(), a very powerful syntax for carrying out the same analysis on different subsets of the full dataset.

```{r}
library(dplyr);library(gapminder)
glimpse(gapminder)
```

```{r}
# Create dataset of 2007 data
gap2007 <- filter(gapminder, year == 2007)

# Compute groupwise mean and median lifeExp
gap2007 %>%
  group_by(continent) %>%
  summarize(mean(lifeExp),
            median(lifeExp)
            )
# Generate box plots of lifeExp for each continent
gap2007 %>%
  ggplot(aes(x = continent , y = lifeExp)) +
  geom_boxplot()
```


Calculate spread measures

Let's extend the powerful group_by() and summarize() syntax to measures of spread. If you're unsure whether you're working with symmetric or skewed distributions, it's a good idea to consider a robust measure like IQR in addition to the usual measures of variance or standard deviation.

The gap2007 dataset that you created in an earlier exercise is available in your workspace.

    For each continent in gap2007, summarize life expectancies using the sd(), the IQR(), and the count of countries, n(). No need to name the new columns produced here. The n() function within your summarize() call does not take any arguments.
    Graphically compare the spread of these distributions by constructing overlaid density plots of life expectancy broken down by continent.

```{r}
# Compute groupwise measures of spread
gap2007 %>%
  group_by(continent) %>%
  summarize(sd(lifeExp),
            IQR(lifeExp),
            n())

# Generate overlaid density plots
gap2007 %>%
  ggplot(aes(x = lifeExp, fill = continent)) +
  geom_density(alpha = 0.3)
```

Choose measures for center and spread

Consider the density plots shown here. What are the most appropriate measures to describe their centers and spreads? In this exercise, you'll select the measures and then calculate them.

Using the shapes of the density plots, calculate the most appropriate measures of center and spread for the following:

    The distribution of life expectancy in the countries of the Americas. Note you'll need to apply a filter here.
    The distribution of country populations across the entire gap2007 dataset.

```{r}
# Compute stats for lifeExp in Americas
gap2007 %>%
  filter(continent == "Americas") %>%
  summarize(mean(lifeExp),
            sd(lifeExp)
            )

# Compute stats for population
gap2007 %>%
  summarize(median(pop),
            IQR(pop)
            )
```
Like mean and standard deviation, **median and IQR** measure the central tendency and spread, respectively, **but are robust to outliers and non-normal data.**

Shape and transformations

Modality; number of prominant humps, unimodal, Bimodal, multimodal, uniform
Skew; tail to right or left or symmetric

```{r}
# Create density plot of old variable
gap2007 %>%
  ggplot(aes(x = pop)) +
  geom_density(alpha = .3)

# Transform the skewed pop variable
gap2007 <- gap2007 %>%
  mutate(log_pop = log(pop))

# Create density plot of new variable
gap2007 %>%
  ggplot(aes(x = log_pop)) +
  geom_density(alpha = .3)
```

Outliers

Extreme values far from the center of the data
Box plots help 
Consider outliers seperately

```{r}
# Create new column and label as outliers
# examples; doesn't run
life <- life %>% 
  mutate(is_outlier = income > 75000 )
life %>%
  filter(is_outlier) %>%
  arrange(desc(income))
# replot without the outliers
life %>%
  filter(!is_outlier) %>%
  ggplot(aes(x = income, fill = west_coast)) +
  geom_density(alpha = 0.3)
```

Identify outliers

Consider the distribution, shown here, of the life expectancies of the countries in Asia. The box plot identifies one clear outlier: a country with a notably low life expectancy. Do you have a guess as to which country this might be? Test your guess in the console using either min() or filter(), then proceed to building a plot with that country removed.

```{r}
head(gap2007)
filter(gap2007, lifeExp == min(lifeExp))

# Filter for Asia, add column indicating outliers
gap_asia <- gap2007 %>%
  filter(continent == "Asia") %>%
  mutate(is_outlier = lifeExp < 50)
# Remove outliers, create box plot of lifeExp
gap_asia %>%
  filter(!is_outlier) %>%
  ggplot(aes(x = 1, y = lifeExp)) +
  geom_boxplot()
```
You have finished the chapter "Numerical Summaries"!

**Case Study**

Introducing the data
Understand each column;
spam; created by a manual review and assumption

Look at histogrmas to determine distribution
  ggplot(data, aes(x = var1)) +
    gemo_historgram() + 
    facet_wrap(~var2)

Box plots for multi dist, **x = 1 to get a single box plt**
  ggplot(data, aes(x = var2, y = var1)) +
    gemo_boxplot ()

Density Plots
  ggplot(data, aes(x = var1)) +
    gemo_boxplot ()

  ggplot(data, aes(x = var1, fill = var2)) +
    gemo_density(alpha = 0.3)
    
Spam and num_char

Is there an association between spam and the length of an email? You could imagine a story either way:

    Spam is more likely to be a short message tempting me to click on a link, or
    My normal email is likely shorter since I exchange brief emails with my friends all the time.

Here, you'll use the email dataset to settle that question. Begin by bringing up the help file and learning about all the variables with ?email.

As you explore the association between spam and the length of an email, use this opportunity to try out linking a dplyr chain with the layers in a ggplot2 object.

Using the email dataset

  Load the packages ggplot2, dplyr, and openintro.
  
  Compute appropriate measures of the center and spread of num_char for both spam and not-spam using group_by() and summarize(). No need to name the new columns created by summarize().
  
  Construct side-by-side box plots to visualize the association between the same two variables. It will be useful to mutate() a new column containing a log-transformed version of num_char.


```{r}
# Load packages
library(ggplot2);library(dplyr);library(openintro)
head(email);?email
```


```{r}
# Compute summary statistics
email %>%
  group_by(spam) %>%
  summarize(median(num_char), IQR(num_char))

# Create plot
email %>%
  mutate(log_num_char = log(num_char)) %>%
  ggplot(aes(x = spam, y = log_num_char)) +
  geom_boxplot()
```
Spam and num_char interpretation

Which of the following interpretations of the plot is valid?
The median length of not-spam emails is greater than that of spam emails.

Spam and !!!

Let's look at a more obvious indicator of spam: exclamation marks. exclaim_mess contains the number of exclamation marks in each message. Using summary statistics and visualization, see if there is a relationship between this variable and whether or not a message is spam.

Experiment with different types of plots until you find one that is the most informative. Recall that you've seen:

    Side-by-side box plots
    Faceted histograms
    Overlaid density plots
    
    Calculate appropriate measures of the center and spread of exclaim_mess for both spam and not-spam using group_by() and summarize().
    Construct an appropriate plot to visualize the association between the same two variables, adding in a log-transformation step if necessary.
    If you decide to use a log transformation, remember that log(0) is -Inf in R, which isn't a very useful value! You can get around this by adding a small number (like .01) to the quantity inside the log() function. This way, your value is never zero. This small shift to the right won't affect your results.

```{r}
# Compute center and spread for exclaim_mess by spam
email %>%
  group_by(spam) %>%
  summarize(median(exclaim_mess),
            IQR(exclaim_mess))

# Create plot for spam and exclaim_mess
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %>%
  ggplot(aes(x = log_exclaim_mess)) +
  geom_histogram() +
  facet_wrap(~ spam)

# Alternative plot: side-by-side box plots
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %>%
  ggplot(aes(x = 1, y = log_exclaim_mess)) +
  geom_boxplot() +
  facet_wrap(~ spam)

# Alternative plot: Overlaid density plots
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %>%
  ggplot(aes(x = log_exclaim_mess, fill = spam)) +
  geom_density(alpha = 0.3)
```
Spam and !!! interpretation

* Which interpretation of these faceted histograms is not correct?

* The most common value of exclaim_mess in both classes of email is zero (a log(exclaim_mess) of -4.6 after adding .01).

* There are more cases of spam in this dataset than not-spam. **<---------**

* Even after a transformation, the distribution of exclaim_mess in both classes of email is right-skewed.

* The typical number of exclamations in the not-spam group appears to be slightly higher than in the spam group.

Zero inflation strategies
Analyze the two components seperately
collapse into two-level categorical variable

Collapsing levels

If it was difficult to work with the heavy skew of exclaim_mess, the number of images attached to each email (image) poses even more of a challenge. Run the following code at the console to get a sense of its distribution:

table(email$image)

Recall that this tabulates the number of cases in each category (so there were 3811 emails with 0 images, for example). Given the very low counts at the higher number of images, let's collapse image into a categorical variable that indicates whether or not the email had at least one image. In this exercise, you'll create this new variable and explore its association with spam.

Starting with email, form a continuous chain that links together the following tasks:

    Create a new variable called has_image that is TRUE where the number of images is greater than zero and FALSE otherwise.
    Create an appropriate plot with email to visualize the relationship between has_image and spam.

```{r}
# Create plot of proportion of spam by image
email %>%
  mutate(has_image = image > 0) %>%
  ggplot(aes(x = has_image, fill = spam)) +
  geom_bar(position = "fill")
```
Image and spam interpretation

Which of the following interpretations of the plot **is** valid?

There are more emails with images than without images.

Emails with images have a higher proportion that are spam than do emails without images.

----> An email without an image is more likely to be not-spam than spam.

Data Integrity

In the process of exploring a dataset, you'll sometimes come across something that will lead you to question how the data were compiled. For example, the variable num_char contains the number of characters in the email, in thousands, so it could take decimal values, but it certainly shouldn't take negative values.

You can formulate a test to ensure this variable is behaving as we expect:

  email$num_char < 0

If you run this code at the console, you'll get a long vector of logical values indicating for each case in the dataset whether that condition is TRUE. Here, the first 1000 values all appear to be FALSE. To verify that all of the cases indeed have non-negative values for num_char, we can take the sum of this vector:

```{r}
sum(email$num_char < 0)
```

This is a handy shortcut. When you do arithmetic on logical values, R treats TRUE as 1 and FALSE as 0. Since the sum over the whole vector is zero, you learn that every case in the dataset took a value of FALSE in the test. That is, the num_char column is behaving as we expect and taking only non-negative values.

Consider the variables image and attach. You can read about them with ?email, but the help file is ambiguous: do attached images count as attached files in this dataset?

Design a simple test to determine if images count as attached files. This involves creating a logical condition to compare the values of the two variables, then using sum() to assess every case in the dataset. Recall that the logical operators are < for less than, <= for less than or equal to, > for greater than, >= for greater than or equal to, and == for equal to.

```{r}
# Test if images count as attachments
  sum(email$image > email$attach)
```

Since image is never greater than attach, we can infer that images are counted as attachments. 

Answering questions with chains

When you have a specific question about a dataset, you can find your way to an answer by carefully constructing the appropriate chain of R code. For example, consider the following question:

    "Within non-spam emails, is the typical length of emails shorter for those that were sent to multiple people?"

This can be answered with the following chain:

```{r}
email %>%
   filter(spam == "not-spam") %>%
   group_by(to_multiple) %>%
   summarize(median(num_char))
```
The code makes it clear that you are using num_char to measure the length of an email and median() as the measure of what is typical. If you run this code, you'll learn that the answer to the question is "yes": the typical length of non-spam sent to multiple people is a bit lower than those sent to only one person.

This chain concluded with summary statistics, but others might end in a plot; it all depends on the question that you're trying to answer.

Build a chain to answer each of the following questions, both about the variable dollar.

    For emails containing the word "dollar", does the typical spam email contain a greater number of occurrences of the word than the typical non-spam email? Create a summary statistic that answers this question.
    
    If you encounter an email with greater than 10 occurrences of the word "dollar", is it more likely to be spam or not-spam? Create a barchart that answers this question.

```{r}
# Question 1
email %>%
  filter(dollar > 0) %>%
  group_by(spam) %>%
  summarize(median(dollar))

# Question 2
email %>%
  filter(dollar > 10) %>%
  ggplot(aes(x = spam)) +
  geom_bar()
```

Ordering bars
```{r}
email <- email %>%
  mutate(zero = exclaim_mess == 0)
levels(email$zero)
email$zero <- factor(email$zero, levels = c("TRUE","FALSE"))
email %>%
  ggplot(aes(x = zero)) +
  geom_bar() +
  facet_wrap(~spam)
```

What's in a number?

Turn your attention to the variable called number. Read more about it by pulling up the help file with ?email.

To explore the association between this variable and spam, select and construct an informative plot. For illustrating relationships between categorical variables, you've seen

    Faceted barcharts
    Side-by-side barcharts
    Stacked and normalized barcharts.

Let's practice constructing a faceted barchart.


Reorder the levels of number so that they preserve the natural ordering of "none", then "small", then "big".

Construct a faceted barchart of the association between number and spam.

```{r}
# Reorder levels
email$number <- factor(email$number, levels = c("none","small","big"))

# Construct plot of number
ggplot(email, aes(x = number)) +
  geom_bar() +
  facet_wrap(~spam)
```

What's in a number interpretation

Which of the following interpretations of the plot **is not** valid?


Given that an email contains a small number, it is more likely to be not-spam.

<---- Given that an email contains no number, it is more likely to be spam.

Given that an email contains a big number, it is more likely to be not-spam.

Within both spam and not-spam, the most common number is a small one.








